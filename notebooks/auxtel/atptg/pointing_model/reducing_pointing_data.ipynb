{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing pointing data\n",
    "\n",
    "During the SUMMIT-4829 run, we obtained data at lower elevation to improve the existing pointing model. \n",
    "\n",
    "The data was taken in a slightly different way. Instead of centering the start in the CCD and storing the data for the pointing model we simply ran the wavefront analysis to collimate the optics, registered the position in the pointing and took an acquisition image, so we could later measure the offset and apply that to the registered position.\n",
    "\n",
    "This notebooks is intended to gather the information about the data taken during the run. Basically we need to all the registered positions in associated acquisition images.\n",
    "\n",
    "The next step will be to measure the position of the brightest start in the field, compute the offset with respect to the center of the field and add that to the data generated by the pointing. This will be done on a separate notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterized notebook\n",
    "\n",
    "This notebook is parameterized, which means it could be run with tools like Papermill as part of a data analysis pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "In order to run this notebook you will need an updated version of `QuickFrameMeasurementTask`. \n",
    "By the time of this writting this library was still not integrated to the DM stack, so you may need to set it up manually. \n",
    "\n",
    "Assuming you are in one of the nublado environments (tts, nts, summit, etc), open a terminal and do the following:\n",
    "\n",
    "```console\n",
    "source ${LOADSTACK}\n",
    "cd ${HOME}/WORK\n",
    "git clone https://github.com/lsst-sitcom/rapid_analysis.git\n",
    "cd rapid_analysis/\n",
    "eups declare -r . -t $USER\n",
    "```\n",
    "\n",
    "Then, on your `${HOME}/notebooks/.user_setups` file, add the following like:\n",
    "\n",
    "```\n",
    "setup rapid_analysis -t $USER\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from astropy.time import Time\n",
    "from astropy import units as u\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import lsst_efd_client\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "from lsst.geom import PointD\n",
    "\n",
    "from lsst.pipe.tasks.quickFrameMeasurement import QuickFrameMeasurementTask\n",
    "\n",
    "from lsst.ts.observing.utilities.auxtel.latiss.getters import get_image\n",
    "from lsst.ts.observing.utilities.auxtel.latiss.utils import (\n",
    "    calculate_xy_offsets,\n",
    "    parse_obs_id,\n",
    ")\n",
    "from lsst.ts.observatory.control.constants.latiss_constants import boresight #, pixel_scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = lsst_efd_client.EfdClient('ldf_stable_efd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Parameters\n",
    "\n",
    "The next cells define the notebook parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date of the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "year=2021\n",
    "month=3\n",
    "day=22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointing file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "pointing_file = f\"data/20210323/AT_point_file_20230323.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define timestamp when the data was taken\n",
    "\n",
    "The next cell defines the dates when the data was taken, it is used by tthe following query to determine when to look for pointing component data registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMIT-4829\n",
    "\n",
    "```\n",
    "start = Time('2021-02-18T00:00:00')\n",
    "end = Time('2021-02-20T00:00:00')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMIT-5025\n",
    "\n",
    "```\n",
    "start = Time('2021-03-22T00:00:00')\n",
    "end = Time('2021-03-25T00:00:00')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = Time(f\"{year}-{month:02d}-{day:02d}T00:00:00\")\n",
    "end = Time(f\"{year}-{month:02d}-{day+3:02d}T00:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "Look from when pointAddData command was sent to the pointing. These will mark the times when we registered the positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = f\"time >= '{start}+00:00' AND time <= '{end}+00:00'\"\n",
    "query = f'SELECT \"private_host\" FROM \"efd\".\"autogen\".\"lsst.sal.ATPtg.command_pointAddData\" WHERE {timestamp}'\n",
    "query_ack = f'SELECT \"cmdtype\", \"ack\" FROM \"efd\".\"autogen\".\"lsst.sal.ATPtg.ackcmd\" WHERE {timestamp} AND cmdtype = 24 AND ack != 300'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query)\n",
    "print(query_ack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_add_data = await client.influx_client.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_add_data_ack = await client.influx_client.query(query_ack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(point_add_data_ack), len(point_add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_ok = []\n",
    "for i in range(len(point_add_data)):\n",
    "    if point_add_data_ack.ack[i] == 303:\n",
    "        print(f\"Command OK: {point_add_data.private_host[i]}\")\n",
    "        command_ok.append(i)\n",
    "    else:\n",
    "        print(f\"Command FAILED: {point_add_data.private_host[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_add_data_ok = point_add_data.loc[point_add_data.index[command_ok]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(point_add_data_ok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding acquisition images\n",
    "\n",
    "Now we have the timestamps for when the telescope position was registered, we need to find the acquisition images.\n",
    "\n",
    "The images where taken before registering the position so we need to look ~40s before the command was sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_obsid = []\n",
    "elevation = []\n",
    "rotator_1 = []\n",
    "rotator_2 = []\n",
    "for time_reg in point_add_data_ok.index:\n",
    "    obsid = await client.select_time_series('lsst.sal.ATArchiver.logevent_imageInOODS', [\"obsid\"], \n",
    "                                     Time(time_reg).tai - timedelta(seconds=40), Time(time_reg).tai + timedelta(seconds=40))\n",
    "    \n",
    "    # It may happen that a image is not taken (or fails to be taken) when we register the position.\n",
    "    # In this cases, add `None` to the acq_obsid list. These data will later be ignored.\n",
    "    if hasattr(obsid, \"obsid\"):\n",
    "        acq_obsid.append(obsid.obsid[-1])\n",
    "    else:\n",
    "        acq_obsid.append(None)\n",
    "\n",
    "    mount_Nasmyth_Encoders = await client.select_packed_time_series(\"lsst.sal.ATMCS.mount_Nasmyth_Encoders\",\n",
    "                                                                    [\"nasmyth1CalculatedAngle\", \n",
    "                                                                     \"nasmyth2CalculatedAngle\"],\n",
    "                                                                    Time(time_reg).tai - timedelta(seconds=40), \n",
    "                                                                    Time(time_reg).tai)\n",
    "    rotator_1.append(np.mean(mount_Nasmyth_Encoders[\"nasmyth1CalculatedAngle\"]))\n",
    "    rotator_2.append(np.mean(mount_Nasmyth_Encoders[\"nasmyth2CalculatedAngle\"]))\n",
    "    elevationCalculatedAngle = await client.select_packed_time_series(\"lsst.sal.ATMCS.mount_AzEl_Encoders\",\n",
    "                                                                      [\"elevationCalculatedAngle\"],\n",
    "                                                                      Time(time_reg).tai - timedelta(seconds=40), \n",
    "                                                                      Time(time_reg).tai\n",
    "                                                                     )\n",
    "    elevation.append(np.mean(elevationCalculatedAngle[\"elevationCalculatedAngle\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data = np.where(np.array([val is not None for val in acq_obsid]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring star position on each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix(angle):\n",
    "    \"\"\"Rotation matrix.\n",
    "    \"\"\"\n",
    "    return np.array(\n",
    "        [\n",
    "            [np.cos(np.radians(angle)), -np.sin(np.radians(angle)), 0.0],\n",
    "            [np.sin(np.radians(angle)), np.cos(np.radians(angle)), 0.0],\n",
    "            [0.0, 0.0, 1.0],\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm_config = QuickFrameMeasurementTask.ConfigClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm = QuickFrameMeasurementTask(config=qm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightest_source_centroid = []\n",
    "exposures = []\n",
    "\n",
    "for obs_id in acq_obsid:\n",
    "    if obs_id is None:\n",
    "        continue\n",
    "    day_obs, seq_num = parse_obs_id(obs_id)[-2:]\n",
    "    exp = await get_image(\n",
    "            dict(dayObs=day_obs, seqNum=seq_num),\n",
    "            datapath=\"/project/shared/auxTel/\",\n",
    "            timeout=10,\n",
    "            runBestEffortIsr=True,\n",
    "        )\n",
    "    result = qm.run(exp)\n",
    "    exposures.append(exp)\n",
    "    brightest_source_centroid.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a plot with the images\n",
    "\n",
    "The next cell will create a plot with the images. The center (boresight) is marked with a \"+\" sign and the position of the brightest source with an open red circly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y_panels = (np.ceil(np.sqrt(len(exposures)))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x_panels = len(exposures) / n_y_panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x_panels, n_y_panels = int(n_x_panels), int(n_y_panels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Contain {len(exposures)} exposures. Will be displayed in a {n_x_panels}x{n_y_panels} grid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "for idx in range(len(exposures)):\n",
    "    axis = plt.subplot(n_x_panels,n_y_panels,idx+1)\n",
    "    plt.imshow(exposures[idx].getImage().array, origin='lower',cmap='gray', norm=LogNorm())\n",
    "    plt.scatter(*brightest_source_centroid[idx].brightestObjCentroid, facecolors='none', s=80,edgecolors='r')\n",
    "    plt.scatter(boresight.getX(), boresight.getY(), marker=\"+\")\n",
    "    axis.set_axis_off()\n",
    "    axis.set_title(f\"[{idx+1}]:{elevation[good_data[idx]]:0.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute azel offset\n",
    "\n",
    "Each entry in `brightest_source_centroid` contains the centroid of thn_x_panelsst source in the field in pixel coordinates.\n",
    "\n",
    "We need to compute the distance to the center of the field and then convert that from xy into azel. It is this azel offset that we need to apply to the pointing table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = np.array(elevation) - np.array(rotator_2) + 90.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will select only the angles for those data points for which we got images above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = angle[good_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azel_correction = np.zeros((2,len(brightest_source_centroid)))\n",
    "\n",
    "for i, source_xy in enumerate(brightest_source_centroid):\n",
    "    dx_arcsec, dy_arcsec = calculate_xy_offsets(PointD(*source_xy.brightestObjCentroid), boresight)\n",
    "\n",
    "    # We are using rotator 2 so we must apply a negative sign on the x-axis offset.\n",
    "    # The equation bellow return offset in elevation/azimuth.\n",
    "    elaz_offset = np.matmul((-dx_arcsec, dy_arcsec), rotation_matrix(angle[i])[:2,:2])*u.arcsec\n",
    "    # We want to store the offset in azel format, so we reverse the result given above.\n",
    "    azel_correction[0][i] = elaz_offset[1].to(u.deg).value\n",
    "    azel_correction[1][i] = elaz_offset[0].to(u.deg).value\n",
    "\n",
    "# The following was verified with the pointing component. When we add an offset of X arcsec in azimuth it \n",
    "# results in a negative offset in the axis. When we make a positive offset in elevation is results in a \n",
    "# positive offset in the axis. The pointing takes care of the cos(elevation) dependency when we apply the\n",
    "# offset, but we need to take care of it here since we want to apply a correction to the axis directly.\n",
    "azel_correction[0] *= -1./np.cos(np.radians(np.array(elevation)[good_data]))\n",
    "azel_correction[1] *= 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply correction to pointing data\n",
    "\n",
    "Now that the offsets are computed in az/el, we need to read the data from the pointing table and apply the offset to the appropriate columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the first `skiprows=4` lines of the file, which contain header information.\n",
    "\n",
    "Read `max_rows=len(point_add_data_ok)`. This avoids the issue of the last line in the pointing file being `END`.\n",
    "\n",
    "In the end get only those data for which there is a paired image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing_file_data = np.loadtxt(\n",
    "    pointing_file,\n",
    "    skiprows=4,\n",
    "    max_rows=len(point_add_data_ok),\n",
    "    unpack=False)[good_data].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_az = pointing_file_data[0]-pointing_file_data[2]\n",
    "delta_el = pointing_file_data[1]-pointing_file_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for az, el, d_az, d_el in zip(delta_az, delta_el, azel_correction[0], azel_correction[1]):\n",
    "    plt.arrow(az, el, -d_az, -d_el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that needs correcting are the 3rd and 4th columns, which contains the correct az and el of the telescope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing_file_data = np.loadtxt(\n",
    "    pointing_file,\n",
    "    skiprows=4,\n",
    "    max_rows=len(point_add_data_ok),\n",
    "    unpack=False)[good_data].T\n",
    "\n",
    "pointing_file_data[2] += azel_correction[0]\n",
    "pointing_file_data[3] += azel_correction[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pointing_file, ext = os.path.splitext(pointing_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_pointing_file, ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add the header and tail of the pointing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = f\"\"\"LSST Auxiliary Telescope, {year} {month} {day} UTC 1 41 1\n",
    ": ALTAZ\n",
    ": ROTNL\n",
    "-30 14 40.3\n",
    "\"\"\"\n",
    "tail = \"END\"\n",
    "with open(f\"{out_pointing_file}_rev{ext}\", \"w\") as fp:\n",
    "    fp.write(header)\n",
    "    np.savetxt(fp, pointing_file_data.T, fmt=\"%011.7f\")\n",
    "    fp.write(tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End\n",
    "\n",
    "The file is now ready to be analysed with tpoint to produce a new pointing model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
